{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahatarinasir/Dayche/blob/master/Auto_encoders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfzQHy6PklRz"
      },
      "source": [
        "# A simple Classification on Mnist Dataset based on a Compact Representation of data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXTLxF9rklR-"
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhk8LOtRklSH"
      },
      "outputs": [],
      "source": [
        "import keras \n",
        "import tensorflow as tf\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from customized_layers import RoughLayer\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPbT96d1klSX"
      },
      "source": [
        "## Mnist data loading "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDANzL-LklSb"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "plt.imshow(x_train[10].reshape(28, 28))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7bsat3nklSe"
      },
      "source": [
        "## Build a simple autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQVhvPDqklSh"
      },
      "outputs": [],
      "source": [
        "input_img = keras.Input(shape=(784,))\n",
        "encoded = keras.layers.Dense(144, activation='relu')(input_img)\n",
        "decoded = keras.layers.Dense(784, activation='sigmoid')(encoded)\n",
        "autoencoder = keras.Model(input_img, decoded)\n",
        "encoder = keras.Model(input_img, encoded)\n",
        "decoder_layer = autoencoder.layers[-1]\n",
        "encoded_input = keras.Input(shape=(144,))\n",
        "decoder = keras.Model(encoded_input, decoder_layer(encoded_input))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyQKhyAvklSl"
      },
      "source": [
        "## Autoencoder training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-e2XwRkklSo",
        "outputId": "e00c03a1-e4f1-4f21-ad48-a3b01de3b6fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.2072 - binary_crossentropy: 0.2072 - val_loss: 0.1289 - val_binary_crossentropy: 0.1289\n",
            "Epoch 2/50\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.1126 - binary_crossentropy: 0.1126 - val_loss: 0.0984 - val_binary_crossentropy: 0.0984\n",
            "Epoch 3/50\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.0927 - binary_crossentropy: 0.0927 - val_loss: 0.0861 - val_binary_crossentropy: 0.0861\n",
            "Epoch 4/50\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.0834 - binary_crossentropy: 0.0834 - val_loss: 0.0796 - val_binary_crossentropy: 0.0796\n",
            "Epoch 5/50\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.0780 - binary_crossentropy: 0.0780 - val_loss: 0.0755 - val_binary_crossentropy: 0.0755\n",
            "Epoch 6/50\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.0748 - binary_crossentropy: 0.0748 - val_loss: 0.0730 - val_binary_crossentropy: 0.0730\n",
            "Epoch 7/50\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.0727 - binary_crossentropy: 0.0727 - val_loss: 0.0714 - val_binary_crossentropy: 0.0714\n",
            "Epoch 8/50\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.0712 - binary_crossentropy: 0.0712 - val_loss: 0.0702 - val_binary_crossentropy: 0.0702\n",
            "Epoch 9/50\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.0702 - binary_crossentropy: 0.0702 - val_loss: 0.0693 - val_binary_crossentropy: 0.0693\n",
            "Epoch 10/50\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.0694 - binary_crossentropy: 0.0694 - val_loss: 0.0686 - val_binary_crossentropy: 0.0686\n",
            "Epoch 11/50\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.0688 - binary_crossentropy: 0.0688 - val_loss: 0.0681 - val_binary_crossentropy: 0.0681\n",
            "Epoch 12/50\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0683 - binary_crossentropy: 0.0683 - val_loss: 0.0677 - val_binary_crossentropy: 0.0677\n",
            "Epoch 13/50\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.0679 - binary_crossentropy: 0.0679 - val_loss: 0.0673 - val_binary_crossentropy: 0.0673\n",
            "Epoch 14/50\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.0675 - binary_crossentropy: 0.0675 - val_loss: 0.0670 - val_binary_crossentropy: 0.0670\n",
            "Epoch 15/50\n",
            "235/235 [==============================] - ETA: 0s - loss: 0.0673 - binary_crossentropy: 0.067 - 2s 8ms/step - loss: 0.0672 - binary_crossentropy: 0.0672 - val_loss: 0.0668 - val_binary_crossentropy: 0.0668\n",
            "Epoch 16/50\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.0670 - binary_crossentropy: 0.0670 - val_loss: 0.0666 - val_binary_crossentropy: 0.0666\n",
            "Epoch 17/50\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.0668 - binary_crossentropy: 0.0668 - val_loss: 0.0664 - val_binary_crossentropy: 0.0664\n",
            "Epoch 18/50\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.0666 - binary_crossentropy: 0.0666 - val_loss: 0.0662 - val_binary_crossentropy: 0.0662\n",
            "Epoch 19/50\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.0665 - binary_crossentropy: 0.0665 - val_loss: 0.0661 - val_binary_crossentropy: 0.0661\n",
            "Epoch 20/50\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.0663 - binary_crossentropy: 0.0663 - val_loss: 0.0660 - val_binary_crossentropy: 0.0660\n",
            "Epoch 21/50\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.0662 - binary_crossentropy: 0.0662 - val_loss: 0.0659 - val_binary_crossentropy: 0.0659\n",
            "Epoch 22/50\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.0661 - binary_crossentropy: 0.0661 - val_loss: 0.0658 - val_binary_crossentropy: 0.0658\n",
            "Epoch 23/50\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.0660 - binary_crossentropy: 0.0660 - val_loss: 0.0657 - val_binary_crossentropy: 0.0657\n",
            "Epoch 24/50\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.0659 - binary_crossentropy: 0.0659 - val_loss: 0.0657 - val_binary_crossentropy: 0.0657\n",
            "Epoch 25/50\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.0658 - binary_crossentropy: 0.0658 - val_loss: 0.0656 - val_binary_crossentropy: 0.0656\n",
            "Epoch 26/50\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.0658 - binary_crossentropy: 0.0658 - val_loss: 0.0655 - val_binary_crossentropy: 0.0655\n",
            "Epoch 27/50\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.0657 - binary_crossentropy: 0.0657 - val_loss: 0.0655 - val_binary_crossentropy: 0.0655\n",
            "Epoch 28/50\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.0656 - binary_crossentropy: 0.0656 - val_loss: 0.0655 - val_binary_crossentropy: 0.0655\n",
            "Epoch 29/50\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.0656 - binary_crossentropy: 0.0656 - val_loss: 0.0654 - val_binary_crossentropy: 0.0654\n",
            "Epoch 30/50\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.0655 - binary_crossentropy: 0.0655 - val_loss: 0.0654 - val_binary_crossentropy: 0.0654\n",
            "Epoch 31/50\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.0655 - binary_crossentropy: 0.0655 - val_loss: 0.0653 - val_binary_crossentropy: 0.0653\n",
            "Epoch 32/50\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.0655 - binary_crossentropy: 0.0655 - val_loss: 0.0652 - val_binary_crossentropy: 0.0652\n",
            "Epoch 33/50\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.0654 - binary_crossentropy: 0.0654 - val_loss: 0.0652 - val_binary_crossentropy: 0.0652\n",
            "Epoch 34/50\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.0654 - binary_crossentropy: 0.0654 - val_loss: 0.0652 - val_binary_crossentropy: 0.0652\n",
            "Epoch 35/50\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.0653 - binary_crossentropy: 0.0653 - val_loss: 0.0652 - val_binary_crossentropy: 0.0652\n",
            "Epoch 36/50\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.0653 - binary_crossentropy: 0.0653 - val_loss: 0.0651 - val_binary_crossentropy: 0.0651\n",
            "Epoch 37/50\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0653 - binary_crossentropy: 0.0653 - val_loss: 0.0652 - val_binary_crossentropy: 0.0652\n",
            "Epoch 38/50\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.0653 - binary_crossentropy: 0.0653 - val_loss: 0.0651 - val_binary_crossentropy: 0.0651\n",
            "Epoch 39/50\n",
            "235/235 [==============================] - 2s 10ms/step - loss: 0.0653 - binary_crossentropy: 0.0653 - val_loss: 0.0651 - val_binary_crossentropy: 0.0651\n",
            "Epoch 40/50\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.0652 - binary_crossentropy: 0.0652 - val_loss: 0.0651 - val_binary_crossentropy: 0.0651\n",
            "Epoch 41/50\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.0652 - binary_crossentropy: 0.0652 - val_loss: 0.0651 - val_binary_crossentropy: 0.0651\n",
            "Epoch 42/50\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0652 - binary_crossentropy: 0.0652 - val_loss: 0.0651 - val_binary_crossentropy: 0.0651\n",
            "Epoch 43/50\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.0652 - binary_crossentropy: 0.0652 - val_loss: 0.0650 - val_binary_crossentropy: 0.0650\n",
            "Epoch 44/50\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.0652 - binary_crossentropy: 0.0652 - val_loss: 0.0651 - val_binary_crossentropy: 0.0651\n",
            "Epoch 45/50\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.0651 - binary_crossentropy: 0.0651 - val_loss: 0.0650 - val_binary_crossentropy: 0.0650\n",
            "Epoch 46/50\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.0651 - binary_crossentropy: 0.0651 - val_loss: 0.0650 - val_binary_crossentropy: 0.0650\n",
            "Epoch 47/50\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0651 - binary_crossentropy: 0.0651 - val_loss: 0.0650 - val_binary_crossentropy: 0.0650\n",
            "Epoch 48/50\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.0651 - binary_crossentropy: 0.0651 - val_loss: 0.0650 - val_binary_crossentropy: 0.0650\n",
            "Epoch 49/50\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.0651 - binary_crossentropy: 0.0651 - val_loss: 0.0650 - val_binary_crossentropy: 0.0650\n",
            "Epoch 50/50\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.0651 - binary_crossentropy: 0.0651 - val_loss: 0.0650 - val_binary_crossentropy: 0.0650\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x202daa40908>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy', metrics = 'binary_crossentropy')\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=50,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yen51KSRklSs"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ta-KsRbkklSv",
        "outputId": "25a833f2-29a4-443c-f107-fc91b5596e0c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x202daefd448>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "encoded_imgs = encoder.predict(x_test)\n",
        "decoded_imgs = decoder.predict(encoded_imgs)\n",
        "plt.subplot(311)\n",
        "plt.imshow(x_test[0].reshape(28, 28))\n",
        "plt.subplot(312)\n",
        "plt.imshow(decoded_imgs[0].reshape(28, 28))\n",
        "plt.subplot(313)\n",
        "plt.imshow(np.uint(encoded_imgs[0].reshape(12, 12)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iI5DFJzklSy"
      },
      "source": [
        "## Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-kkF2DoklS0",
        "outputId": "c7af85a3-190f-4960-b8a5-680ca6702d98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 144)\n",
            "Epoch 1/100\n",
            "1875/1875 [==============================] - 2s 958us/step - loss: 0.1234 - accuracy: 0.8009 - val_loss: 0.0679 - val_accuracy: 0.9039\n",
            "Epoch 2/100\n",
            "1875/1875 [==============================] - 2s 946us/step - loss: 0.0636 - accuracy: 0.9084 - val_loss: 0.0593 - val_accuracy: 0.9127\n",
            "Epoch 3/100\n",
            "1875/1875 [==============================] - 2s 969us/step - loss: 0.0531 - accuracy: 0.9237 - val_loss: 0.0538 - val_accuracy: 0.9263\n",
            "Epoch 4/100\n",
            "1875/1875 [==============================] - 2s 971us/step - loss: 0.0465 - accuracy: 0.9340 - val_loss: 0.0425 - val_accuracy: 0.9398\n",
            "Epoch 5/100\n",
            "1875/1875 [==============================] - 2s 945us/step - loss: 0.0420 - accuracy: 0.9402 - val_loss: 0.0404 - val_accuracy: 0.9455\n",
            "Epoch 6/100\n",
            "1875/1875 [==============================] - 2s 934us/step - loss: 0.0386 - accuracy: 0.9459 - val_loss: 0.0367 - val_accuracy: 0.9505\n",
            "Epoch 7/100\n",
            "1875/1875 [==============================] - 2s 966us/step - loss: 0.0359 - accuracy: 0.9493 - val_loss: 0.0343 - val_accuracy: 0.9553\n",
            "Epoch 8/100\n",
            "1875/1875 [==============================] - 2s 939us/step - loss: 0.0338 - accuracy: 0.9537 - val_loss: 0.0359 - val_accuracy: 0.9497\n",
            "Epoch 9/100\n",
            "1875/1875 [==============================] - 2s 935us/step - loss: 0.0323 - accuracy: 0.9552 - val_loss: 0.0356 - val_accuracy: 0.9519\n",
            "Epoch 10/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0307 - accuracy: 0.9586 - val_loss: 0.0311 - val_accuracy: 0.9569\n",
            "Epoch 11/100\n",
            "1875/1875 [==============================] - 2s 984us/step - loss: 0.0296 - accuracy: 0.9595 - val_loss: 0.0326 - val_accuracy: 0.9560\n",
            "Epoch 12/100\n",
            "1875/1875 [==============================] - 2s 971us/step - loss: 0.0285 - accuracy: 0.9609 - val_loss: 0.0311 - val_accuracy: 0.9572\n",
            "Epoch 13/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0278 - accuracy: 0.9618 - val_loss: 0.0304 - val_accuracy: 0.9595\n",
            "Epoch 14/100\n",
            "1875/1875 [==============================] - 2s 966us/step - loss: 0.0269 - accuracy: 0.9638 - val_loss: 0.0294 - val_accuracy: 0.9602\n",
            "Epoch 15/100\n",
            "1875/1875 [==============================] - 2s 960us/step - loss: 0.0262 - accuracy: 0.9649 - val_loss: 0.0292 - val_accuracy: 0.9602\n",
            "Epoch 16/100\n",
            "1875/1875 [==============================] - 2s 959us/step - loss: 0.0256 - accuracy: 0.9663 - val_loss: 0.0283 - val_accuracy: 0.9599\n",
            "Epoch 17/100\n",
            "1875/1875 [==============================] - 2s 963us/step - loss: 0.0252 - accuracy: 0.9664 - val_loss: 0.0282 - val_accuracy: 0.9636\n",
            "Epoch 18/100\n",
            "1875/1875 [==============================] - 2s 980us/step - loss: 0.0245 - accuracy: 0.9671 - val_loss: 0.0301 - val_accuracy: 0.9616\n",
            "Epoch 19/100\n",
            "1875/1875 [==============================] - 2s 986us/step - loss: 0.0243 - accuracy: 0.9683 - val_loss: 0.0285 - val_accuracy: 0.9615\n",
            "Epoch 20/100\n",
            "1875/1875 [==============================] - 2s 983us/step - loss: 0.0239 - accuracy: 0.9688 - val_loss: 0.0272 - val_accuracy: 0.9636\n",
            "Epoch 21/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0234 - accuracy: 0.9691 - val_loss: 0.0291 - val_accuracy: 0.9620\n",
            "Epoch 22/100\n",
            "1875/1875 [==============================] - 2s 984us/step - loss: 0.0230 - accuracy: 0.9696 - val_loss: 0.0302 - val_accuracy: 0.9624\n",
            "Epoch 23/100\n",
            "1875/1875 [==============================] - 1s 723us/step - loss: 0.0229 - accuracy: 0.9704 - val_loss: 0.0270 - val_accuracy: 0.9650\n",
            "Epoch 24/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0227 - accuracy: 0.9699 - val_loss: 0.0316 - val_accuracy: 0.9572\n",
            "Epoch 25/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0221 - accuracy: 0.9711 - val_loss: 0.0297 - val_accuracy: 0.9611\n",
            "Epoch 26/100\n",
            "1875/1875 [==============================] - 2s 997us/step - loss: 0.0218 - accuracy: 0.9718 - val_loss: 0.0293 - val_accuracy: 0.9629\n",
            "Epoch 27/100\n",
            "1875/1875 [==============================] - 2s 977us/step - loss: 0.0218 - accuracy: 0.9720 - val_loss: 0.0300 - val_accuracy: 0.9609\n",
            "Epoch 28/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0217 - accuracy: 0.9726 - val_loss: 0.0263 - val_accuracy: 0.9676\n",
            "Epoch 29/100\n",
            "1875/1875 [==============================] - 2s 966us/step - loss: 0.0213 - accuracy: 0.9725 - val_loss: 0.0257 - val_accuracy: 0.9677\n",
            "Epoch 30/100\n",
            "1875/1875 [==============================] - 2s 984us/step - loss: 0.0212 - accuracy: 0.9730 - val_loss: 0.0262 - val_accuracy: 0.9663\n",
            "Epoch 31/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0208 - accuracy: 0.9740 - val_loss: 0.0266 - val_accuracy: 0.9666\n",
            "Epoch 32/100\n",
            "1875/1875 [==============================] - 2s 994us/step - loss: 0.0209 - accuracy: 0.9733 - val_loss: 0.0275 - val_accuracy: 0.9659\n",
            "Epoch 33/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0207 - accuracy: 0.9736 - val_loss: 0.0247 - val_accuracy: 0.9687\n",
            "Epoch 34/100\n",
            "1875/1875 [==============================] - 2s 963us/step - loss: 0.0205 - accuracy: 0.9743 - val_loss: 0.0261 - val_accuracy: 0.9670\n",
            "Epoch 35/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0202 - accuracy: 0.9749 - val_loss: 0.0288 - val_accuracy: 0.9643\n",
            "Epoch 36/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0201 - accuracy: 0.9744 - val_loss: 0.0264 - val_accuracy: 0.9665\n",
            "Epoch 37/100\n",
            "1875/1875 [==============================] - 2s 928us/step - loss: 0.0202 - accuracy: 0.9744 - val_loss: 0.0279 - val_accuracy: 0.9658\n",
            "Epoch 38/100\n",
            "1875/1875 [==============================] - 2s 959us/step - loss: 0.0199 - accuracy: 0.9752 - val_loss: 0.0300 - val_accuracy: 0.9627\n",
            "Epoch 39/100\n",
            "1875/1875 [==============================] - 2s 963us/step - loss: 0.0197 - accuracy: 0.9753 - val_loss: 0.0259 - val_accuracy: 0.9677\n",
            "Epoch 40/100\n",
            "1875/1875 [==============================] - 2s 948us/step - loss: 0.0196 - accuracy: 0.9755 - val_loss: 0.0261 - val_accuracy: 0.9674\n",
            "Epoch 41/100\n",
            "1875/1875 [==============================] - 2s 942us/step - loss: 0.0195 - accuracy: 0.9754 - val_loss: 0.0254 - val_accuracy: 0.9683\n",
            "Epoch 42/100\n",
            "1875/1875 [==============================] - 2s 940us/step - loss: 0.0193 - accuracy: 0.9759 - val_loss: 0.0264 - val_accuracy: 0.9667\n",
            "Epoch 43/100\n",
            "1875/1875 [==============================] - 2s 942us/step - loss: 0.0192 - accuracy: 0.9766 - val_loss: 0.0254 - val_accuracy: 0.9674\n",
            "Epoch 44/100\n",
            "1875/1875 [==============================] - 2s 920us/step - loss: 0.0190 - accuracy: 0.9765 - val_loss: 0.0263 - val_accuracy: 0.9672\n",
            "Epoch 45/100\n",
            "1875/1875 [==============================] - 2s 934us/step - loss: 0.0191 - accuracy: 0.9762 - val_loss: 0.0253 - val_accuracy: 0.9668\n",
            "Epoch 46/100\n",
            "1875/1875 [==============================] - 2s 920us/step - loss: 0.0188 - accuracy: 0.9768 - val_loss: 0.0261 - val_accuracy: 0.9666\n",
            "Epoch 47/100\n",
            "1875/1875 [==============================] - 2s 942us/step - loss: 0.0189 - accuracy: 0.9767 - val_loss: 0.0246 - val_accuracy: 0.9670\n",
            "Epoch 48/100\n",
            "1875/1875 [==============================] - 2s 927us/step - loss: 0.0189 - accuracy: 0.9766 - val_loss: 0.0255 - val_accuracy: 0.9692\n",
            "Epoch 49/100\n",
            "1875/1875 [==============================] - 2s 928us/step - loss: 0.0187 - accuracy: 0.9772 - val_loss: 0.0262 - val_accuracy: 0.9682\n",
            "Epoch 50/100\n",
            "1875/1875 [==============================] - 2s 941us/step - loss: 0.0187 - accuracy: 0.9765 - val_loss: 0.0298 - val_accuracy: 0.9630\n",
            "Epoch 51/100\n",
            "1875/1875 [==============================] - 2s 998us/step - loss: 0.0185 - accuracy: 0.9770 - val_loss: 0.0274 - val_accuracy: 0.9668\n",
            "Epoch 52/100\n",
            "1875/1875 [==============================] - 2s 936us/step - loss: 0.0186 - accuracy: 0.9769 - val_loss: 0.0274 - val_accuracy: 0.9648\n",
            "Epoch 53/100\n",
            "1875/1875 [==============================] - 2s 925us/step - loss: 0.0184 - accuracy: 0.9772 - val_loss: 0.0246 - val_accuracy: 0.9703\n",
            "Epoch 54/100\n",
            "1875/1875 [==============================] - 2s 951us/step - loss: 0.0184 - accuracy: 0.9774 - val_loss: 0.0265 - val_accuracy: 0.9678\n",
            "Epoch 55/100\n",
            "1875/1875 [==============================] - 2s 945us/step - loss: 0.0184 - accuracy: 0.9776 - val_loss: 0.0271 - val_accuracy: 0.9664\n",
            "Epoch 56/100\n",
            "1875/1875 [==============================] - 2s 886us/step - loss: 0.0181 - accuracy: 0.9776 - val_loss: 0.0255 - val_accuracy: 0.9675\n",
            "Epoch 57/100\n",
            "1875/1875 [==============================] - 2s 912us/step - loss: 0.0183 - accuracy: 0.9776 - val_loss: 0.0259 - val_accuracy: 0.9662\n",
            "Epoch 58/100\n",
            "1875/1875 [==============================] - 2s 885us/step - loss: 0.0180 - accuracy: 0.9775 - val_loss: 0.0253 - val_accuracy: 0.9690\n",
            "Epoch 59/100\n",
            "1875/1875 [==============================] - 2s 910us/step - loss: 0.0180 - accuracy: 0.9774 - val_loss: 0.0271 - val_accuracy: 0.9667\n",
            "Epoch 60/100\n",
            "1875/1875 [==============================] - 2s 909us/step - loss: 0.0180 - accuracy: 0.9787 - val_loss: 0.0245 - val_accuracy: 0.9692\n",
            "Epoch 61/100\n",
            "1875/1875 [==============================] - 2s 913us/step - loss: 0.0182 - accuracy: 0.9779 - val_loss: 0.0252 - val_accuracy: 0.9680\n",
            "Epoch 62/100\n",
            "1875/1875 [==============================] - 2s 881us/step - loss: 0.0177 - accuracy: 0.9785 - val_loss: 0.0259 - val_accuracy: 0.9676\n",
            "Epoch 63/100\n",
            "1875/1875 [==============================] - 2s 949us/step - loss: 0.0177 - accuracy: 0.9788 - val_loss: 0.0243 - val_accuracy: 0.9699\n",
            "Epoch 64/100\n",
            "1875/1875 [==============================] - 2s 945us/step - loss: 0.0181 - accuracy: 0.9783 - val_loss: 0.0299 - val_accuracy: 0.9636\n",
            "Epoch 65/100\n",
            "1875/1875 [==============================] - 2s 900us/step - loss: 0.0176 - accuracy: 0.9787 - val_loss: 0.0271 - val_accuracy: 0.9678\n",
            "Epoch 66/100\n",
            "1875/1875 [==============================] - 2s 903us/step - loss: 0.0175 - accuracy: 0.9790 - val_loss: 0.0268 - val_accuracy: 0.9667\n",
            "Epoch 67/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0175 - accuracy: 0.9791 - val_loss: 0.0267 - val_accuracy: 0.9680\n",
            "Epoch 68/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0174 - accuracy: 0.9790 - val_loss: 0.0252 - val_accuracy: 0.9697\n",
            "Epoch 69/100\n",
            "1875/1875 [==============================] - 2s 927us/step - loss: 0.0177 - accuracy: 0.9786 - val_loss: 0.0269 - val_accuracy: 0.9662\n",
            "Epoch 70/100\n",
            "1875/1875 [==============================] - 2s 950us/step - loss: 0.0173 - accuracy: 0.9791 - val_loss: 0.0269 - val_accuracy: 0.9669\n",
            "Epoch 71/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0172 - accuracy: 0.9795 - val_loss: 0.0270 - val_accuracy: 0.9671\n",
            "Epoch 72/100\n",
            "1875/1875 [==============================] - 2s 937us/step - loss: 0.0172 - accuracy: 0.9797 - val_loss: 0.0258 - val_accuracy: 0.9686\n",
            "Epoch 73/100\n",
            "1875/1875 [==============================] - 2s 892us/step - loss: 0.0171 - accuracy: 0.9792 - val_loss: 0.0266 - val_accuracy: 0.9687\n",
            "Epoch 74/100\n",
            "1875/1875 [==============================] - 2s 946us/step - loss: 0.0172 - accuracy: 0.9792 - val_loss: 0.0246 - val_accuracy: 0.9688\n",
            "Epoch 75/100\n",
            "1875/1875 [==============================] - 2s 925us/step - loss: 0.0172 - accuracy: 0.9790 - val_loss: 0.0257 - val_accuracy: 0.9690\n",
            "Epoch 76/100\n",
            "1875/1875 [==============================] - 2s 895us/step - loss: 0.0171 - accuracy: 0.9796 - val_loss: 0.0262 - val_accuracy: 0.9682\n",
            "Epoch 77/100\n",
            "1875/1875 [==============================] - 2s 910us/step - loss: 0.0170 - accuracy: 0.9795 - val_loss: 0.0289 - val_accuracy: 0.9669\n",
            "Epoch 78/100\n",
            "1875/1875 [==============================] - 2s 942us/step - loss: 0.0170 - accuracy: 0.9799 - val_loss: 0.0260 - val_accuracy: 0.9693\n",
            "Epoch 79/100\n",
            "1875/1875 [==============================] - 2s 942us/step - loss: 0.0169 - accuracy: 0.9797 - val_loss: 0.0261 - val_accuracy: 0.9690\n",
            "Epoch 80/100\n",
            "1875/1875 [==============================] - 2s 922us/step - loss: 0.0167 - accuracy: 0.9803 - val_loss: 0.0257 - val_accuracy: 0.9697\n",
            "Epoch 81/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0170 - accuracy: 0.9795 - val_loss: 0.0262 - val_accuracy: 0.9680\n",
            "Epoch 82/100\n",
            "1875/1875 [==============================] - 2s 890us/step - loss: 0.0167 - accuracy: 0.9800 - val_loss: 0.0251 - val_accuracy: 0.9682\n",
            "Epoch 83/100\n",
            "1875/1875 [==============================] - 2s 928us/step - loss: 0.0168 - accuracy: 0.9804 - val_loss: 0.0258 - val_accuracy: 0.9700\n",
            "Epoch 84/100\n",
            "1875/1875 [==============================] - 2s 859us/step - loss: 0.0166 - accuracy: 0.9806 - val_loss: 0.0256 - val_accuracy: 0.9698\n",
            "Epoch 85/100\n",
            "1875/1875 [==============================] - 2s 897us/step - loss: 0.0167 - accuracy: 0.9797 - val_loss: 0.0257 - val_accuracy: 0.9690\n",
            "Epoch 86/100\n",
            "1875/1875 [==============================] - 2s 890us/step - loss: 0.0169 - accuracy: 0.9804 - val_loss: 0.0268 - val_accuracy: 0.9680\n",
            "Epoch 87/100\n",
            "1875/1875 [==============================] - 2s 873us/step - loss: 0.0166 - accuracy: 0.9809 - val_loss: 0.0247 - val_accuracy: 0.9702\n",
            "Epoch 88/100\n",
            "1875/1875 [==============================] - 2s 895us/step - loss: 0.0164 - accuracy: 0.9806 - val_loss: 0.0268 - val_accuracy: 0.9684\n",
            "Epoch 89/100\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0165 - accuracy: 0.9801 - val_loss: 0.0244 - val_accuracy: 0.9711\n",
            "Epoch 90/100\n",
            "1875/1875 [==============================] - 2s 913us/step - loss: 0.0167 - accuracy: 0.9799 - val_loss: 0.0258 - val_accuracy: 0.9690\n",
            "Epoch 91/100\n",
            "1875/1875 [==============================] - 2s 892us/step - loss: 0.0164 - accuracy: 0.9808 - val_loss: 0.0247 - val_accuracy: 0.9702\n",
            "Epoch 92/100\n",
            "1875/1875 [==============================] - 2s 887us/step - loss: 0.0166 - accuracy: 0.9803 - val_loss: 0.0278 - val_accuracy: 0.9665\n",
            "Epoch 93/100\n",
            "1875/1875 [==============================] - 2s 883us/step - loss: 0.0164 - accuracy: 0.9804 - val_loss: 0.0252 - val_accuracy: 0.9691\n",
            "Epoch 94/100\n",
            "1875/1875 [==============================] - 2s 867us/step - loss: 0.0162 - accuracy: 0.9812 - val_loss: 0.0256 - val_accuracy: 0.9687\n",
            "Epoch 95/100\n",
            "1875/1875 [==============================] - 2s 893us/step - loss: 0.0165 - accuracy: 0.9805 - val_loss: 0.0259 - val_accuracy: 0.9706\n",
            "Epoch 96/100\n",
            "1875/1875 [==============================] - 2s 908us/step - loss: 0.0162 - accuracy: 0.9807 - val_loss: 0.0265 - val_accuracy: 0.9680\n",
            "Epoch 97/100\n",
            "1875/1875 [==============================] - 2s 892us/step - loss: 0.0161 - accuracy: 0.9811 - val_loss: 0.0260 - val_accuracy: 0.9694\n",
            "Epoch 98/100\n",
            "1875/1875 [==============================] - 2s 886us/step - loss: 0.0162 - accuracy: 0.9809 - val_loss: 0.0255 - val_accuracy: 0.9701\n",
            "Epoch 99/100\n",
            "1875/1875 [==============================] - 2s 898us/step - loss: 0.0163 - accuracy: 0.9804 - val_loss: 0.0257 - val_accuracy: 0.9696\n",
            "Epoch 100/100\n",
            "1875/1875 [==============================] - 2s 874us/step - loss: 0.0160 - accuracy: 0.9814 - val_loss: 0.0274 - val_accuracy: 0.9683\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x20302d08c08>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train_encoded, x_test_encoded = encoder(x_train), encoder(x_test)\n",
        "print(x_train_encoded.shape)\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Dense(50, activation = 'relu'))\n",
        "model.add(keras.layers.Dense(10, activation = 'softmax'))\n",
        "# y = model(x_train_encoded)\n",
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = 'accuracy')\n",
        "model.fit(x_train_encoded, tf.keras.utils.to_categorical(y_train), \n",
        "          validation_data = (x_test_encoded, tf.keras.utils.to_categorical(y_test)), \n",
        "          epochs = 100, \n",
        "          batch_size = 32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuJePUtxklS3"
      },
      "source": [
        "## Evaluation of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3n8a1X0YklS4",
        "outputId": "7b9d1a50-c223-41d2-e275-c167660ce4ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 970    0    3    1    3    4    9    1    7    6]\n",
            " [   0 1124    2    0    0    0    3    4    1    5]\n",
            " [   1    3 1005    6    5    1    4   14    7    1]\n",
            " [   1    3    7  987    0   27    0    4    6   12]\n",
            " [   1    0    1    0  963    0    9    2    4   24]\n",
            " [   1    1    0    6    0  842   10    0    3    2]\n",
            " [   1    2    1    0    1    5  915    0    1    0]\n",
            " [   1    0    9    6    2    3    1  999    8   15]\n",
            " [   3    2    3    4    2    8    6    1  936    2]\n",
            " [   1    0    1    0    6    2    1    3    1  942]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.97      0.98      1004\n",
            "           1       0.99      0.99      0.99      1139\n",
            "           2       0.97      0.96      0.97      1047\n",
            "           3       0.98      0.94      0.96      1047\n",
            "           4       0.98      0.96      0.97      1004\n",
            "           5       0.94      0.97      0.96       865\n",
            "           6       0.96      0.99      0.97       926\n",
            "           7       0.97      0.96      0.96      1044\n",
            "           8       0.96      0.97      0.96       967\n",
            "           9       0.93      0.98      0.96       957\n",
            "\n",
            "    accuracy                           0.97     10000\n",
            "   macro avg       0.97      0.97      0.97     10000\n",
            "weighted avg       0.97      0.97      0.97     10000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pre_te = model.predict(x_test_encoded)\n",
        "print(confusion_matrix(np.argmax(y_pre_te, axis = 1), y_test))\n",
        "print(classification_report(np.argmax(y_pre_te, axis = 1), y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TwF9YwpklS6"
      },
      "source": [
        "# A simple Classification on Breast Cancer Dataset based on a Compact Representation of data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irRiJKrGklS7"
      },
      "source": [
        "## Data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JiQL7P1oklS9"
      },
      "outputs": [],
      "source": [
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
        "scaler = MinMaxScaler().fit(X_train)\n",
        "X_train, X_test = scaler.transform(X_train), scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJpmeNxaklS-"
      },
      "outputs": [],
      "source": [
        "\n",
        "input_m = keras.Input(shape=(30,))\n",
        "encoded = keras.layers.Dense(2, activation='sigmoid')(input_m)\n",
        "decoded = keras.layers.Dense(30, activation='linear')(encoded)\n",
        "autoencoder = keras.Model(input_m, decoded)\n",
        "encoder = keras.Model(input_m, encoded)\n",
        "decoder_layer = autoencoder.layers[-1]\n",
        "encoded_input = keras.Input(shape=(2,))\n",
        "decoder = keras.Model(encoded_input, decoder_layer(encoded_input))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8OROf67klTA",
        "outputId": "46a8eb16-1b58-4cb3-995d-0bc4851fd4ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.0942 - mse: 0.0942 - val_loss: 0.0781 - val_mse: 0.0781\n",
            "Epoch 2/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0544 - mse: 0.0544 - val_loss: 0.0528 - val_mse: 0.0528\n",
            "Epoch 3/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0380 - mse: 0.0380 - val_loss: 0.0408 - val_mse: 0.0408\n",
            "Epoch 4/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0341 - val_mse: 0.0341\n",
            "Epoch 5/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0302 - val_mse: 0.0302\n",
            "Epoch 6/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0278 - val_mse: 0.0278\n",
            "Epoch 7/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0262 - val_mse: 0.0262\n",
            "Epoch 8/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0249 - val_mse: 0.0249\n",
            "Epoch 9/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0240 - val_mse: 0.0240\n",
            "Epoch 10/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0232 - val_mse: 0.0232\n",
            "Epoch 11/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0225 - val_mse: 0.0225\n",
            "Epoch 12/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0217 - val_mse: 0.0217\n",
            "Epoch 13/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0210 - val_mse: 0.0210\n",
            "Epoch 14/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0202 - val_mse: 0.0202\n",
            "Epoch 15/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0195 - val_mse: 0.0195\n",
            "Epoch 16/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0188 - val_mse: 0.0188\n",
            "Epoch 17/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0181 - val_mse: 0.0181\n",
            "Epoch 18/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0175 - val_mse: 0.0175\n",
            "Epoch 19/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0170 - val_mse: 0.0170\n",
            "Epoch 20/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0163 - val_mse: 0.0163\n",
            "Epoch 21/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0159 - val_mse: 0.0159\n",
            "Epoch 22/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0154 - val_mse: 0.0154\n",
            "Epoch 23/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0150 - val_mse: 0.0150\n",
            "Epoch 24/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0147 - val_mse: 0.0147\n",
            "Epoch 25/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0144 - val_mse: 0.0144\n",
            "Epoch 26/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0140 - val_mse: 0.0140\n",
            "Epoch 27/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0137 - val_mse: 0.0137\n",
            "Epoch 28/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0134 - val_mse: 0.0134\n",
            "Epoch 29/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0131 - val_mse: 0.0131\n",
            "Epoch 30/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0129 - val_mse: 0.0129\n",
            "Epoch 31/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0127 - val_mse: 0.0127\n",
            "Epoch 32/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0124 - val_mse: 0.0124\n",
            "Epoch 33/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0122 - val_mse: 0.0122\n",
            "Epoch 34/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0120 - val_mse: 0.0120\n",
            "Epoch 35/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0118 - val_mse: 0.0118\n",
            "Epoch 36/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0116 - val_mse: 0.0116\n",
            "Epoch 37/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0114 - val_mse: 0.0114\n",
            "Epoch 38/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0112 - val_mse: 0.0112\n",
            "Epoch 39/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0110 - val_mse: 0.0110\n",
            "Epoch 40/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0108 - val_mse: 0.0108\n",
            "Epoch 41/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0106 - val_mse: 0.0106\n",
            "Epoch 42/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0105 - val_mse: 0.0105\n",
            "Epoch 43/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0103 - val_mse: 0.0103\n",
            "Epoch 44/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0101 - val_mse: 0.0101\n",
            "Epoch 45/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0100 - val_mse: 0.0100\n",
            "Epoch 46/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0098 - val_mse: 0.0098\n",
            "Epoch 47/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0096 - val_mse: 0.0096\n",
            "Epoch 48/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0095 - val_mse: 0.0095\n",
            "Epoch 49/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0093 - val_mse: 0.0093\n",
            "Epoch 50/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0092 - val_mse: 0.0092\n",
            "Epoch 51/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0091 - val_mse: 0.0091\n",
            "Epoch 52/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0090 - val_mse: 0.0090\n",
            "Epoch 53/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0089 - val_mse: 0.0089\n",
            "Epoch 54/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0088 - val_mse: 0.0088\n",
            "Epoch 55/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0087 - val_mse: 0.0087\n",
            "Epoch 56/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0087 - val_mse: 0.0087\n",
            "Epoch 57/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0086 - val_mse: 0.0086\n",
            "Epoch 58/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0085 - val_mse: 0.0085\n",
            "Epoch 59/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0084 - val_mse: 0.0084\n",
            "Epoch 60/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0084 - val_mse: 0.0084\n",
            "Epoch 61/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0083 - val_mse: 0.0083\n",
            "Epoch 62/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0083 - val_mse: 0.0083\n",
            "Epoch 63/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0082 - val_mse: 0.0082\n",
            "Epoch 64/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0082 - val_mse: 0.0082\n",
            "Epoch 65/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0081 - val_mse: 0.0081\n",
            "Epoch 66/100\n",
            "80/80 [==============================] - 0s 994us/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0081 - val_mse: 0.0081\n",
            "Epoch 67/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0081 - val_mse: 0.0081\n",
            "Epoch 68/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0080 - val_mse: 0.0080\n",
            "Epoch 69/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0080 - val_mse: 0.0080\n",
            "Epoch 70/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0080 - val_mse: 0.0080\n",
            "Epoch 71/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0080 - val_mse: 0.0080\n",
            "Epoch 72/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0080 - val_mse: 0.0080\n",
            "Epoch 73/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0079 - val_mse: 0.0079\n",
            "Epoch 74/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0079 - val_mse: 0.0079\n",
            "Epoch 75/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0079 - val_mse: 0.0079\n",
            "Epoch 76/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0078 - val_mse: 0.0078\n",
            "Epoch 77/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0078 - val_mse: 0.0078\n",
            "Epoch 78/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0078 - val_mse: 0.0078\n",
            "Epoch 79/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0078 - val_mse: 0.0078\n",
            "Epoch 80/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0078 - val_mse: 0.0078\n",
            "Epoch 81/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0077 - val_mse: 0.0077\n",
            "Epoch 82/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0077 - val_mse: 0.0077\n",
            "Epoch 83/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0077 - val_mse: 0.0077\n",
            "Epoch 84/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0077 - val_mse: 0.0077\n",
            "Epoch 85/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0077 - val_mse: 0.0077\n",
            "Epoch 86/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0077 - val_mse: 0.0077\n",
            "Epoch 87/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0077 - val_mse: 0.0077\n",
            "Epoch 88/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0076 - val_mse: 0.0076\n",
            "Epoch 89/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0076 - val_mse: 0.0076\n",
            "Epoch 90/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0076 - val_mse: 0.0076\n",
            "Epoch 91/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0076 - val_mse: 0.0076\n",
            "Epoch 92/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0076 - val_mse: 0.0076\n",
            "Epoch 93/100\n",
            "80/80 [==============================] - 0s 999us/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0076 - val_mse: 0.0076\n",
            "Epoch 94/100\n",
            "80/80 [==============================] - 0s 954us/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0075 - val_mse: 0.0075\n",
            "Epoch 95/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0076 - val_mse: 0.0076\n",
            "Epoch 96/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0076 - val_mse: 0.0076\n",
            "Epoch 97/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0076 - val_mse: 0.0076\n",
            "Epoch 98/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0076 - val_mse: 0.0076\n",
            "Epoch 99/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0075 - val_mse: 0.0075\n",
            "Epoch 100/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0075 - val_mse: 0.0075\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x20303391e48>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "autoencoder.compile(optimizer='adam', loss='mse', metrics = 'mse')\n",
        "autoencoder.fit(X_train, X_train,\n",
        "                epochs=100,\n",
        "                batch_size=5,\n",
        "                shuffle=True,\n",
        "                validation_data=(X_test, X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnP9FHsYklTB"
      },
      "outputs": [],
      "source": [
        "encoded_x_test = encoder(X_test)\n",
        "encoded_x_train = encoder(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-9sUBJjklTC",
        "outputId": "3411c6f2-24bd-4826-f1fb-635671d380f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6634 - accuracy: 0.6482 - val_loss: 0.6481 - val_accuracy: 0.6257\n",
            "Epoch 2/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.6295 - accuracy: 0.6457 - val_loss: 0.6194 - val_accuracy: 0.6784\n",
            "Epoch 3/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.6040 - accuracy: 0.6784 - val_loss: 0.5967 - val_accuracy: 0.7310\n",
            "Epoch 4/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.5818 - accuracy: 0.7312 - val_loss: 0.5766 - val_accuracy: 0.7427\n",
            "Epoch 5/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.5612 - accuracy: 0.7286 - val_loss: 0.5565 - val_accuracy: 0.7602\n",
            "Epoch 6/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.5412 - accuracy: 0.7588 - val_loss: 0.5366 - val_accuracy: 0.7719\n",
            "Epoch 7/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.5222 - accuracy: 0.7839 - val_loss: 0.5167 - val_accuracy: 0.7895\n",
            "Epoch 8/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.5017 - accuracy: 0.7990 - val_loss: 0.4972 - val_accuracy: 0.8012\n",
            "Epoch 9/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4824 - accuracy: 0.8291 - val_loss: 0.4780 - val_accuracy: 0.8187\n",
            "Epoch 10/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4631 - accuracy: 0.8417 - val_loss: 0.4587 - val_accuracy: 0.8304\n",
            "Epoch 11/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4440 - accuracy: 0.8618 - val_loss: 0.4400 - val_accuracy: 0.8480\n",
            "Epoch 12/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4261 - accuracy: 0.8819 - val_loss: 0.4221 - val_accuracy: 0.8480\n",
            "Epoch 13/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4082 - accuracy: 0.8819 - val_loss: 0.4048 - val_accuracy: 0.8655\n",
            "Epoch 14/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.3913 - accuracy: 0.8920 - val_loss: 0.3887 - val_accuracy: 0.8772\n",
            "Epoch 15/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.3755 - accuracy: 0.8894 - val_loss: 0.3735 - val_accuracy: 0.8772\n",
            "Epoch 16/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.3608 - accuracy: 0.8995 - val_loss: 0.3594 - val_accuracy: 0.8947\n",
            "Epoch 17/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.3467 - accuracy: 0.8995 - val_loss: 0.3460 - val_accuracy: 0.9123\n",
            "Epoch 18/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.3336 - accuracy: 0.9146 - val_loss: 0.3335 - val_accuracy: 0.9123\n",
            "Epoch 19/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.3214 - accuracy: 0.9146 - val_loss: 0.3222 - val_accuracy: 0.9123\n",
            "Epoch 20/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.3094 - accuracy: 0.9196 - val_loss: 0.3113 - val_accuracy: 0.9123\n",
            "Epoch 21/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.2990 - accuracy: 0.9246 - val_loss: 0.3015 - val_accuracy: 0.9181\n",
            "Epoch 22/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.2895 - accuracy: 0.9196 - val_loss: 0.2923 - val_accuracy: 0.9181\n",
            "Epoch 23/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.2803 - accuracy: 0.9246 - val_loss: 0.2836 - val_accuracy: 0.9298\n",
            "Epoch 24/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.2711 - accuracy: 0.9221 - val_loss: 0.2755 - val_accuracy: 0.9357\n",
            "Epoch 25/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.2629 - accuracy: 0.9271 - val_loss: 0.2681 - val_accuracy: 0.9357\n",
            "Epoch 26/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.2558 - accuracy: 0.9296 - val_loss: 0.2611 - val_accuracy: 0.9357\n",
            "Epoch 27/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.2485 - accuracy: 0.9271 - val_loss: 0.2547 - val_accuracy: 0.9357\n",
            "Epoch 28/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.2429 - accuracy: 0.9296 - val_loss: 0.2489 - val_accuracy: 0.9415\n",
            "Epoch 29/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.2363 - accuracy: 0.9397 - val_loss: 0.2431 - val_accuracy: 0.9357\n",
            "Epoch 30/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.2314 - accuracy: 0.9347 - val_loss: 0.2379 - val_accuracy: 0.9415\n",
            "Epoch 31/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.2254 - accuracy: 0.9397 - val_loss: 0.2330 - val_accuracy: 0.9415\n",
            "Epoch 32/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.2205 - accuracy: 0.9422 - val_loss: 0.2286 - val_accuracy: 0.9415\n",
            "Epoch 33/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.2165 - accuracy: 0.9372 - val_loss: 0.2244 - val_accuracy: 0.9415\n",
            "Epoch 34/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.2121 - accuracy: 0.9447 - val_loss: 0.2205 - val_accuracy: 0.9415\n",
            "Epoch 35/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.2081 - accuracy: 0.9372 - val_loss: 0.2167 - val_accuracy: 0.9415\n",
            "Epoch 36/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.2043 - accuracy: 0.9397 - val_loss: 0.2133 - val_accuracy: 0.9415\n",
            "Epoch 37/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.2013 - accuracy: 0.9422 - val_loss: 0.2100 - val_accuracy: 0.9415\n",
            "Epoch 38/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1974 - accuracy: 0.9447 - val_loss: 0.2068 - val_accuracy: 0.9415\n",
            "Epoch 39/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.1950 - accuracy: 0.9422 - val_loss: 0.2040 - val_accuracy: 0.9415\n",
            "Epoch 40/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1918 - accuracy: 0.9447 - val_loss: 0.2011 - val_accuracy: 0.9415\n",
            "Epoch 41/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1887 - accuracy: 0.9447 - val_loss: 0.1985 - val_accuracy: 0.9415\n",
            "Epoch 42/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1867 - accuracy: 0.9422 - val_loss: 0.1961 - val_accuracy: 0.9357\n",
            "Epoch 43/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1843 - accuracy: 0.9422 - val_loss: 0.1939 - val_accuracy: 0.9415\n",
            "Epoch 44/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.1822 - accuracy: 0.9397 - val_loss: 0.1916 - val_accuracy: 0.9357\n",
            "Epoch 45/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1798 - accuracy: 0.9397 - val_loss: 0.1896 - val_accuracy: 0.9357\n",
            "Epoch 46/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.1774 - accuracy: 0.9447 - val_loss: 0.1877 - val_accuracy: 0.9357\n",
            "Epoch 47/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.1754 - accuracy: 0.9447 - val_loss: 0.1859 - val_accuracy: 0.9415\n",
            "Epoch 48/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.1740 - accuracy: 0.9397 - val_loss: 0.1842 - val_accuracy: 0.9415\n",
            "Epoch 49/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1723 - accuracy: 0.9447 - val_loss: 0.1825 - val_accuracy: 0.9415\n",
            "Epoch 50/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1707 - accuracy: 0.9422 - val_loss: 0.1809 - val_accuracy: 0.9415\n",
            "Epoch 51/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1697 - accuracy: 0.9447 - val_loss: 0.1797 - val_accuracy: 0.9415\n",
            "Epoch 52/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1679 - accuracy: 0.9472 - val_loss: 0.1780 - val_accuracy: 0.9415\n",
            "Epoch 53/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1663 - accuracy: 0.9422 - val_loss: 0.1765 - val_accuracy: 0.9415\n",
            "Epoch 54/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1646 - accuracy: 0.9447 - val_loss: 0.1752 - val_accuracy: 0.9415\n",
            "Epoch 55/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1643 - accuracy: 0.9472 - val_loss: 0.1742 - val_accuracy: 0.9415\n",
            "Epoch 56/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1621 - accuracy: 0.9497 - val_loss: 0.1726 - val_accuracy: 0.9415\n",
            "Epoch 57/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1615 - accuracy: 0.9422 - val_loss: 0.1715 - val_accuracy: 0.9415\n",
            "Epoch 58/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1604 - accuracy: 0.9447 - val_loss: 0.1704 - val_accuracy: 0.9415\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 59/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1594 - accuracy: 0.9447 - val_loss: 0.1693 - val_accuracy: 0.9415\n",
            "Epoch 60/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1586 - accuracy: 0.9472 - val_loss: 0.1682 - val_accuracy: 0.9415\n",
            "Epoch 61/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1575 - accuracy: 0.9447 - val_loss: 0.1672 - val_accuracy: 0.9415\n",
            "Epoch 62/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1561 - accuracy: 0.9472 - val_loss: 0.1664 - val_accuracy: 0.9415\n",
            "Epoch 63/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1553 - accuracy: 0.9447 - val_loss: 0.1654 - val_accuracy: 0.9415\n",
            "Epoch 64/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1545 - accuracy: 0.9447 - val_loss: 0.1646 - val_accuracy: 0.9415\n",
            "Epoch 65/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1542 - accuracy: 0.9497 - val_loss: 0.1637 - val_accuracy: 0.9415\n",
            "Epoch 66/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.1530 - accuracy: 0.9447 - val_loss: 0.1628 - val_accuracy: 0.9415\n",
            "Epoch 67/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.1521 - accuracy: 0.9523 - val_loss: 0.1619 - val_accuracy: 0.9415\n",
            "Epoch 68/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.1515 - accuracy: 0.9447 - val_loss: 0.1612 - val_accuracy: 0.9415\n",
            "Epoch 69/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1507 - accuracy: 0.9497 - val_loss: 0.1604 - val_accuracy: 0.9415\n",
            "Epoch 70/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1502 - accuracy: 0.9447 - val_loss: 0.1598 - val_accuracy: 0.9415\n",
            "Epoch 71/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.9497 - val_loss: 0.1591 - val_accuracy: 0.9415\n",
            "Epoch 72/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.1486 - accuracy: 0.9523 - val_loss: 0.1584 - val_accuracy: 0.9415\n",
            "Epoch 73/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1480 - accuracy: 0.9497 - val_loss: 0.1577 - val_accuracy: 0.9415\n",
            "Epoch 74/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1473 - accuracy: 0.9523 - val_loss: 0.1570 - val_accuracy: 0.9415\n",
            "Epoch 75/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1469 - accuracy: 0.9523 - val_loss: 0.1563 - val_accuracy: 0.9415\n",
            "Epoch 76/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1467 - accuracy: 0.9447 - val_loss: 0.1557 - val_accuracy: 0.9415\n",
            "Epoch 77/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1458 - accuracy: 0.9523 - val_loss: 0.1552 - val_accuracy: 0.9415\n",
            "Epoch 78/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1456 - accuracy: 0.9447 - val_loss: 0.1547 - val_accuracy: 0.9415\n",
            "Epoch 79/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1450 - accuracy: 0.9548 - val_loss: 0.1541 - val_accuracy: 0.9415\n",
            "Epoch 80/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1439 - accuracy: 0.9497 - val_loss: 0.1535 - val_accuracy: 0.9415\n",
            "Epoch 81/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1439 - accuracy: 0.9472 - val_loss: 0.1530 - val_accuracy: 0.9415\n",
            "Epoch 82/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1438 - accuracy: 0.9472 - val_loss: 0.1527 - val_accuracy: 0.9357\n",
            "Epoch 83/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1430 - accuracy: 0.9472 - val_loss: 0.1520 - val_accuracy: 0.9415\n",
            "Epoch 84/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1426 - accuracy: 0.9523 - val_loss: 0.1515 - val_accuracy: 0.9415\n",
            "Epoch 85/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1420 - accuracy: 0.9447 - val_loss: 0.1510 - val_accuracy: 0.9415\n",
            "Epoch 86/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1420 - accuracy: 0.9447 - val_loss: 0.1506 - val_accuracy: 0.9415\n",
            "Epoch 87/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1419 - accuracy: 0.9497 - val_loss: 0.1502 - val_accuracy: 0.9415\n",
            "Epoch 88/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1415 - accuracy: 0.9422 - val_loss: 0.1498 - val_accuracy: 0.9415\n",
            "Epoch 89/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1412 - accuracy: 0.9497 - val_loss: 0.1498 - val_accuracy: 0.9415\n",
            "Epoch 90/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1404 - accuracy: 0.9497 - val_loss: 0.1491 - val_accuracy: 0.9415\n",
            "Epoch 91/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1402 - accuracy: 0.9497 - val_loss: 0.1487 - val_accuracy: 0.9415\n",
            "Epoch 92/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1400 - accuracy: 0.9447 - val_loss: 0.1483 - val_accuracy: 0.9415\n",
            "Epoch 93/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.1399 - accuracy: 0.9497 - val_loss: 0.1480 - val_accuracy: 0.9357\n",
            "Epoch 94/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.1389 - accuracy: 0.9497 - val_loss: 0.1475 - val_accuracy: 0.9415\n",
            "Epoch 95/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1390 - accuracy: 0.9472 - val_loss: 0.1471 - val_accuracy: 0.9415\n",
            "Epoch 96/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1381 - accuracy: 0.9497 - val_loss: 0.1469 - val_accuracy: 0.9415\n",
            "Epoch 97/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1390 - accuracy: 0.9497 - val_loss: 0.1472 - val_accuracy: 0.9474\n",
            "Epoch 98/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1382 - accuracy: 0.9447 - val_loss: 0.1462 - val_accuracy: 0.9415\n",
            "Epoch 99/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1379 - accuracy: 0.9497 - val_loss: 0.1460 - val_accuracy: 0.9474\n",
            "Epoch 100/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.1371 - accuracy: 0.9497 - val_loss: 0.1454 - val_accuracy: 0.9415\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x2030375c108>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier = keras.models.Sequential()\n",
        "classifier.add(keras.layers.Dense(5, activation = 'relu'))\n",
        "classifier.add(keras.layers.Dense(1, activation = 'sigmoid'))\n",
        "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = 'accuracy')\n",
        "classifier.fit(encoded_x_train, y_train, validation_data = (encoded_x_test, y_test), epochs = 100, batch_size = 5 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIvYlUCYklTE",
        "outputId": "bac1af31-1bbd-44f6-abc7-0e44e4b4f90d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 59   2]\n",
            " [  8 102]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.97      0.92        61\n",
            "         1.0       0.98      0.93      0.95       110\n",
            "\n",
            "    accuracy                           0.94       171\n",
            "   macro avg       0.93      0.95      0.94       171\n",
            "weighted avg       0.95      0.94      0.94       171\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pre = classifier.predict(encoded_x_test)\n",
        "y_pre[y_pre >= 0.5] = 1\n",
        "y_pre[y_pre < 0.5] = 0\n",
        "print(confusion_matrix(y_pre, y_test))\n",
        "print(classification_report(y_pre, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7m-1onjklTG"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tboN81IOklTH"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsqTL80eklTI"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Auto-encoders.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}